{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means++\n",
    "\n",
    "In this notebook, we are going to implement [k-means++](https://en.wikipedia.org/wiki/K-means%2B%2B) algorithm with multiple initial sets. The original k-means++ algorithm will just sample one set of initial centroid points and iterate until the result converges. The only difference in this implementation is that we will sample `RUNS` sets of initial centroid points and update them in parallel. The procedure will finish when all centroid sets are converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Definition of some global parameters.\n",
    "K = 5  # Number of centroids\n",
    "RUNS = 25  # Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RANDOM_SEED = 60295531\n",
    "converge_dist = 0.1 # The K-means algorithm is terminated when the change in the location \n",
    "                    # of the centroids is smaller than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def print_log(s):\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def parse_data(row):\n",
    "    '''\n",
    "    Parse each pandas row into a tuple of (station_name, feature_vec),\n",
    "    where feature_vec is the concatenation of the projection vectors\n",
    "    of TAVG, TRANGE, and SNWD.\n",
    "    '''\n",
    "    return (row[0],\n",
    "            np.concatenate([row[1], row[2], row[3]]))\n",
    "\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)\n",
    "\n",
    "\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()\n",
    "    shape = rdd.take(1)[0][1].shape[0]\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "\n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2\n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "\n",
    "\n",
    "    # The second element `dist` in the tuple below is the closest distance from\n",
    "    # each data point to the selected points in the initial set, where `dist[i]`\n",
    "    # is the closest distance to the points in the i-th initial set.\n",
    "    data = rdd.map(lambda p: (p, [np.inf] * RUNS)) \\\n",
    "              .cache()\n",
    "\n",
    "    # Collect the feature vectors of all data points beforehand, might be\n",
    "    # useful in the following for-loop\n",
    "    local_data = rdd.map(lambda (name, vec): vec).collect()\n",
    "\n",
    "    # Randomly select the first point for every run of k-means++,\n",
    "    # i.e. randomly select `RUNS` points and add it to the `centers` variable\n",
    "    sample = [local_data[k] for k in np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "\n",
    "    for idx in range(K - 1):\n",
    "        ##############################################################################\n",
    "        # Insert your code here:\n",
    "        data = data.map(lambda (datas, dist) : (datas, update_dist(datas[1], dist, idx)))\n",
    "        distance = np.array(data.values().collect())\n",
    "        norm_distance = distance/distance.sum(axis=0)\n",
    "        for i in range(RUNS):\n",
    "            k = choice(norm_distance[:,i])\n",
    "            centers[i, idx+1] = local_data[k]\n",
    "        ##############################################################################\n",
    "        # In each iteration, you need to select one point for each set\n",
    "        # of initial points (so select `RUNS` points in total).\n",
    "        # For each data point x, let D_i(x) be the distance between x and\n",
    "        # the nearest center that has already been added to the i-th set.\n",
    "        # Choose a new data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional to D_i(x)^2\n",
    "        ##############################################################################\n",
    "        # pass\n",
    "    \n",
    "    return centers\n",
    "\n",
    "\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices the nearest centroids of `p`.\n",
    "    `centers` contains sets of centroids, where `centers[i]` is\n",
    "    the i-th set of centroids.\n",
    "    '''\n",
    "    best = [0] * len(centers)\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for idx in range(len(centers)):\n",
    "        for j in range(len(centers[0])):\n",
    "            temp_dist = norm(p - centers[idx][j])\n",
    "            if temp_dist < closest[idx]:\n",
    "                closest[idx] = temp_dist\n",
    "                best[idx] = j\n",
    "    return best\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    \n",
    "    # following code use new_points\n",
    "    new_points = {}\n",
    "    local_data = np.array(rdd.map(lambda (name, vec): vec).collect())\n",
    "    \n",
    "    while temp_dist > converge_dist:\n",
    "        ##############################################################################\n",
    "        # INSERT YOUR CODE HERE\n",
    "        ##############################################################################\n",
    "        \n",
    "        # Update all `RUNS` sets of centroids using standard k-means algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th centroids set\n",
    "        #   - Average all points that are assigned to the same centroid\n",
    "        #   - Update the centroid with the average of all points that are assigned to it\n",
    "        \n",
    "        # Insert your code here\n",
    "        closet_idxs_rdd = rdd.map(lambda (name, vec) : get_closest(vec, k_points)) # points * RUNS\n",
    "        closet_idxs = np.array(closet_idxs_rdd.collect()) # points * RUNS\n",
    "        \n",
    "        for i in range(RUNS):\n",
    "            for j in range(K):\n",
    "                idxs = closet_idxs[:, i] == j\n",
    "                new_points[(i, j)] = local_data[idxs].mean(axis=0)\n",
    "#         def help(p):\n",
    "#             pairs = enumerate(get_closest(p, k_points))\n",
    "#             return [(pr, (p,1)) for pr in pairs]\n",
    "#         new_points = rdd.flatMap(lambda p: help(p[1])) \\\n",
    "#                     .reduceByKey(lambda x, y:(x[0]+y[0], x[1]+y[1])) \\\n",
    "#                     .map(lambda x:(x[0], x[1][0]/x[1][1])) \\\n",
    "#                     .collect()\n",
    "\n",
    "        # You can modify this statement as long as `temp_dist` equals to\n",
    "        # max( sum( l2_norm of the movement of j-th centroid in each centroids set ))\n",
    "        ##############################################################################\n",
    "\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[idx][j] - new_points[(idx, j)]) for j in range(K)])\n",
    "                    for idx in range(RUNS)])\n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((idx, j), p) in new_points.items():\n",
    "            k_points[idx][j] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'USC00044534', array([  3.04796236e+03,   1.97434852e+03,   1.50560792e+02,\n",
       "          -2.90363288e+03,  -2.36907268e+02,   1.47021791e+02,\n",
       "           1.91503001e-01,   1.87262808e-01,  -4.01379553e-02]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data\n",
    "data = pickle.load(open(\"../../Data/Weather/stations_projections.pickle\", \"rb\"))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in data.iterrows()])\n",
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized.\n",
      "Iteration 5 max shift: 2677.35 (time: 23.40)\n",
      "Iteration 10 max shift: 2156.44 (time: 23.77)\n",
      "Iteration 15 max shift: 1373.75 (time: 24.57)\n",
      "Iteration 20 max shift: 636.86 (time: 23.23)\n",
      "Iteration 25 max shift: 451.38 (time: 23.15)\n",
      "Iteration 30 max shift: 237.27 (time: 23.36)\n",
      "Iteration 35 max shift: 184.37 (time: 23.43)\n",
      "Iteration 40 max shift: 37.08 (time: 23.24)\n",
      "Iteration 45 max shift: 44.61 (time: 23.32)\n",
      "Iteration 50 max shift: 10.48 (time: 23.17)\n",
      "Iteration 55 max shift: 3.65 (time: 23.46)\n",
      "Time takes to converge: 284.367590904\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "centroids = kmeans(rdd, K, RUNS, converge_dist, np.random.randint(1000))\n",
    "group = rdd.mapValues(lambda p: get_closest(p, centroids)) \\\n",
    "           .collect()\n",
    "\n",
    "print \"Time takes to converge:\", time.time() - st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your results\n",
    "Verify your results by computing the objective function of the k-means clustering problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cost(rdd, centers):\n",
    "    '''\n",
    "    Compute the square of l2 norm from each data point in `rdd`\n",
    "    to the centroids in `centers`\n",
    "    '''\n",
    "    def _get_cost(p, centers):\n",
    "        best = [0] * len(centers)\n",
    "        closest = [np.inf] * len(centers)\n",
    "        for idx in range(len(centers)):\n",
    "            for j in range(len(centers[0])):\n",
    "                temp_dist = norm(p - centers[idx][j])\n",
    "                if temp_dist < closest[idx]:\n",
    "                    closest[idx] = temp_dist\n",
    "                    best[idx] = j\n",
    "        return np.array(closest)**2\n",
    "    \n",
    "    cost = rdd.map(lambda (name, v): _get_cost(v, centroids)).collect()\n",
    "    return np.array(cost).sum(axis=0)\n",
    "\n",
    "cost = get_cost(rdd, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.8254902123 33.7575332525 33.7632782289\n"
     ]
    }
   ],
   "source": [
    "log2 = np.log2\n",
    "\n",
    "print log2(np.max(cost)), log2(np.min(cost)), log2(np.mean(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the increase of entropy after multiple runs of k-means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = []\n",
    "\n",
    "for i in range(RUNS):\n",
    "    count = {}\n",
    "    for g, sig in group:\n",
    "        _s = ','.join(map(str, sig[:(i + 1)]))\n",
    "        count[_s] = count.get(_s, 0) + 1\n",
    "    entropy.append(compute_entropy(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Remove this cell before submitting to PyBolt (PyBolt does not fully support matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9657287651773423"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhf8P1AonfNFqZ4EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f43790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.plot(range(1, RUNS + 1), entropy)\n",
    "2**entropy[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy= [1.6445469704935676, 1.6445469704935676, 2.0674170627025292, 2.0674170627025297, 2.0674170627025292, 2.0674170627025297, 2.0674170627025297, 2.0674170627025297, 2.0674170627025297, 2.0674170627025297, 2.0674170627025301, 2.0674170627025297, 2.0674170627025297, 2.0674170627025292, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727686, 2.1640389721727691, 2.2079748799839716, 2.2079748799839716, 2.3120054617120385, 2.3120054617120385, 2.312005461712038]\n",
      "best_centers= [array([ 1492.0570036 ,  1954.30230067,    94.48584365, -2567.99675086,\n",
      "        -112.2682711 ,   152.28015089,   395.84574671,   131.09390181,\n",
      "          73.10315542]), array([   408.29696084,   1353.92836359,     56.37619358,  -2206.17029272,\n",
      "         -221.37785013,    183.25193705,  18757.57406286,  -5513.4828535 ,\n",
      "         1476.58182765]), array([ 2952.76608   ,  1933.02980077,    92.424188  , -2547.74851278,\n",
      "         144.84123959,   154.0172669 ,    18.40817384,     7.84926361,\n",
      "           5.11113863]), array([  750.10763916,  2067.97627806,    35.34601332, -2398.58742321,\n",
      "        -138.36631381,   233.32209536,  2268.85311051,   245.99611499,\n",
      "         125.46432194]), array([  428.4738994 ,  1807.58033164,    35.14799298, -2574.43476306,\n",
      "        -180.39839191,   263.09089521,  6048.90511888,  -743.20856056,\n",
      "         256.68319372])]\n"
     ]
    }
   ],
   "source": [
    "print 'entropy=',entropy\n",
    "best = np.argmin(cost)\n",
    "print 'best_centers=',list(centroids[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
